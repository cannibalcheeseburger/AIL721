{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 43\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenizer(text):\n",
    "    return re.findall(r'\\b\\w+\\b', str(text).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 1490, Test samples: 735\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"Datasets/TrainData.csv\")\n",
    "test_df = pd.read_csv(\"Datasets/TestLabels.csv\")\n",
    "\n",
    "train_df.dropna(subset=['Text', 'Category'], inplace=True)\n",
    "test_df.dropna(subset=['Text', 'Label - (business, tech, politics, sport, entertainment)'], inplace=True)\n",
    "\n",
    "print(f\"Train samples: {len(train_df)}, Test samples: {len(test_df)}\")\n",
    "\n",
    "train_texts = train_df['Text'].tolist()\n",
    "train_labels = train_df['Category'].tolist()\n",
    "test_texts = test_df['Text'].tolist()\n",
    "test_labels = test_df['Label - (business, tech, politics, sport, entertainment)'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = [simple_tokenizer(t) for t in train_texts]\n",
    "test_tokenized = [simple_tokenizer(t) for t in test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(inner_array) for inner_array in train_tokenized]\n",
    "max_len = int(np.percentile(lengths, 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, tokenized_text, labels, vocab=None, label2idx=None, max_len=300):\n",
    "        self.texts = tokenized_text\n",
    "        self.max_len = max_len\n",
    "        if vocab is None:\n",
    "            words = [word for text in self.texts for word in text]\n",
    "            word_freq = Counter(words)\n",
    "            self.vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "            for word in word_freq:\n",
    "                self.vocab[word] = len(self.vocab)\n",
    "        else:\n",
    "            self.vocab = vocab\n",
    "\n",
    "        self.texts = [self.encode(text) for text in self.texts]\n",
    "\n",
    "        if label2idx is None:\n",
    "            unique_labels = sorted(set(label for label in labels if pd.notna(label)))\n",
    "            self.label2idx = {label: i for i, label in enumerate(unique_labels)}\n",
    "        else:\n",
    "            self.label2idx = label2idx\n",
    "\n",
    "        self.labels = [self.label2idx[label] for label in labels if pd.notna(label)]\n",
    "\n",
    "    def encode(self, tokens):\n",
    "        encoded = [self.vocab.get(tok, self.vocab['<UNK>']) for tok in tokens]\n",
    "        return encoded[:self.max_len] + [0]*(self.max_len - len(encoded))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.texts[idx]), torch.tensor(self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = NewsDataset(train_tokenized, train_labels)\n",
    "test_data = NewsDataset(test_tokenized, test_labels, vocab=train_data.vocab, label2idx=train_data.label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_classes,ls_layer=64):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.conv = nn.Conv1d(embed_dim, 128, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm = nn.LSTM(128, 128, batch_first=True, bidirectional=True,dropout=0.3)\n",
    "        self.attn_fc = nn.Linear(256, 1)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)  # Add dropout\n",
    "        self.bn = nn.BatchNorm1d(128)  # After conv layer\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)              \n",
    "        x = x.permute(0, 2, 1)           \n",
    "        x = self.relu(self.conv(x))    \n",
    "        x = self.dropout(x)  # After embedding/conv layers\n",
    "   \n",
    "        x = x.permute(0, 2, 1)             \n",
    "        lstm_out, _ = self.lstm(x)        # (B, T, 2H)\n",
    "        x = torch.tanh(lstm_out)\n",
    "        attn_weights = torch.softmax(self.attn_fc(x), dim=1)  # (B, T, 1)\n",
    "        context = torch.sum(attn_weights * x, dim=1)          # (B, 2H)\n",
    "        return self.fc(context)           # (B, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for texts, labels in loader:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    return avg_train_loss , train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, criterion):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    all_preds ,all_labels = [] ,[]\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().tolist())\n",
    "            all_labels.extend(y_batch.cpu().tolist())\n",
    "\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    f1 = f1_score(all_labels,all_preds,average='micro')\n",
    "    return avg_loss, accuracy,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "lr = 0.0003\n",
    "weight_decay = 1e-3\n",
    "ls_layer = 64\n",
    "hidden = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kashp\\miniconda3\\envs\\dla3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model\n",
    "model = CLSTM(len(train_data.vocab), embed_dim=512, num_classes=len(train_data.label2idx),\n",
    "              ).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr,weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 1.5432 | Train Acc: 28.26% | Val Loss: 1.4705 | Val Acc: 37.28% | f1: 0.37\n",
      "Epoch 2/50 | Train Loss: 1.2365 | Train Acc: 55.84% | Val Loss: 0.9742 | Val Acc: 58.78% | f1: 0.59\n",
      "Epoch 3/50 | Train Loss: 0.6462 | Train Acc: 78.26% | Val Loss: 0.6424 | Val Acc: 73.61% | f1: 0.74\n",
      "Epoch 4/50 | Train Loss: 0.3932 | Train Acc: 87.72% | Val Loss: 0.4253 | Val Acc: 85.44% | f1: 0.85\n",
      "Epoch 5/50 | Train Loss: 0.2316 | Train Acc: 94.30% | Val Loss: 0.3918 | Val Acc: 86.67% | f1: 0.87\n",
      "Epoch 6/50 | Train Loss: 0.1836 | Train Acc: 94.63% | Val Loss: 0.3414 | Val Acc: 88.98% | f1: 0.89\n",
      "Epoch 7/50 | Train Loss: 0.1376 | Train Acc: 95.77% | Val Loss: 0.3418 | Val Acc: 89.25% | f1: 0.89\n",
      "Epoch 8/50 | Train Loss: 0.0775 | Train Acc: 97.99% | Val Loss: 0.3478 | Val Acc: 88.71% | f1: 0.89\n",
      "Epoch 9/50 | Train Loss: 0.0701 | Train Acc: 98.39% | Val Loss: 0.3116 | Val Acc: 90.61% | f1: 0.91\n",
      "Epoch 10/50 | Train Loss: 0.1319 | Train Acc: 97.52% | Val Loss: 0.3190 | Val Acc: 89.25% | f1: 0.89\n",
      "Epoch 11/50 | Train Loss: 0.1022 | Train Acc: 97.65% | Val Loss: 0.2870 | Val Acc: 91.02% | f1: 0.91\n",
      "Epoch 12/50 | Train Loss: 0.0460 | Train Acc: 99.19% | Val Loss: 0.2586 | Val Acc: 91.16% | f1: 0.91\n",
      "Epoch 13/50 | Train Loss: 0.0228 | Train Acc: 99.73% | Val Loss: 0.2899 | Val Acc: 91.29% | f1: 0.91\n",
      "Epoch 14/50 | Train Loss: 0.0277 | Train Acc: 99.26% | Val Loss: 0.3374 | Val Acc: 89.93% | f1: 0.90\n",
      "Epoch 15/50 | Train Loss: 0.0194 | Train Acc: 99.60% | Val Loss: 0.3090 | Val Acc: 91.02% | f1: 0.91\n",
      "Epoch 16/50 | Train Loss: 0.0092 | Train Acc: 99.93% | Val Loss: 0.3431 | Val Acc: 91.16% | f1: 0.91\n",
      "Epoch 17/50 | Train Loss: 0.0100 | Train Acc: 99.93% | Val Loss: 0.3560 | Val Acc: 88.84% | f1: 0.89\n",
      "Epoch 18/50 | Train Loss: 0.0091 | Train Acc: 99.87% | Val Loss: 0.3494 | Val Acc: 90.88% | f1: 0.91\n",
      "Epoch 19/50 | Train Loss: 0.0546 | Train Acc: 98.05% | Val Loss: 0.4891 | Val Acc: 85.31% | f1: 0.85\n",
      "Epoch 20/50 | Train Loss: 0.0709 | Train Acc: 98.39% | Val Loss: 0.3080 | Val Acc: 90.75% | f1: 0.91\n",
      "Epoch 21/50 | Train Loss: 0.0100 | Train Acc: 99.93% | Val Loss: 0.3058 | Val Acc: 91.43% | f1: 0.91\n",
      "Epoch 22/50 | Train Loss: 0.0052 | Train Acc: 100.00% | Val Loss: 0.2885 | Val Acc: 92.11% | f1: 0.92\n",
      "Epoch 23/50 | Train Loss: 0.0042 | Train Acc: 100.00% | Val Loss: 0.3362 | Val Acc: 91.70% | f1: 0.92\n",
      "Epoch 24/50 | Train Loss: 0.0030 | Train Acc: 100.00% | Val Loss: 0.3166 | Val Acc: 92.24% | f1: 0.92\n",
      "Epoch 25/50 | Train Loss: 0.0094 | Train Acc: 99.87% | Val Loss: 0.4359 | Val Acc: 88.16% | f1: 0.88\n",
      "Epoch 26/50 | Train Loss: 0.0073 | Train Acc: 99.80% | Val Loss: 0.3402 | Val Acc: 91.16% | f1: 0.91\n",
      "Epoch 27/50 | Train Loss: 0.0021 | Train Acc: 100.00% | Val Loss: 0.3321 | Val Acc: 91.56% | f1: 0.92\n",
      "Early stopping at epoch 26. Best val loss: 0.2586\n"
     ]
    }
   ],
   "source": [
    "patience = 15 \n",
    "best_val_loss = float('inf')\n",
    "counter = 0  \n",
    "for epoch in range(EPOCHS):\n",
    "    avg_train_loss , train_accuracy = train_model(model, train_loader, criterion, optimizer, device)\n",
    "    avg_val_loss, val_accuracy ,f1 = evaluate_model(model, test_loader, criterion)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.2f}% | \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.2f}% | f1: {f1:.2f}\")\n",
    "    \n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        counter = 0  # Reset patience counter\n",
    "        best_model = model.state_dict()  # Save best model\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch}. Best val loss: {best_val_loss:.4f}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Micro F1 Score = 0.9156\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation and confusion matrix\n",
    "avg_val_loss, val_accuracy, f1 = evaluate_model(model, test_loader, criterion)\n",
    "print(f\"\\nFinal Micro F1 Score = {f1:.4f}\")\n",
    "label_names = [label for label, _ in sorted(train_data.label2idx.items(), key=lambda x: x[1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dla3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
