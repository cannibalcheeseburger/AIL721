{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset,random_split\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Loading the training data\n",
    "with open('train.pkl', 'rb') as file:\n",
    "    train_data = pickle.load(file)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, data,):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.data[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNISTDataset(train_data)\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "\n",
    "# Use random_split to divide the dataset\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_dataloader:\n",
    "    # Access a single image and label from the batch\n",
    "    single_image = images[0]  # Get the first image in the batch\n",
    "    single_label = labels[0]  # Get the first label in the batch\n",
    "    break  # Stop after getting one batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1750800d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(single_image.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,input_size=28*28,hidden_units=64,output_size=10):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units,hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units,output_size),\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=28*28\n",
    "hidden_units=64\n",
    "output_size=10\n",
    "model = MLP().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.3420, Accuracy: 90.03%\n",
      "Validation Loss: 0.2343, Validation Accuracy: 92.85% \n",
      "\n",
      "Epoch [2/50], Loss: 0.1561, Accuracy: 95.19%\n",
      "Validation Loss: 0.1709, Validation Accuracy: 95.08% \n",
      "\n",
      "Epoch [3/50], Loss: 0.1105, Accuracy: 96.57%\n",
      "Validation Loss: 0.1409, Validation Accuracy: 95.76% \n",
      "\n",
      "Epoch [4/50], Loss: 0.0829, Accuracy: 97.39%\n",
      "Validation Loss: 0.1186, Validation Accuracy: 96.60% \n",
      "\n",
      "Epoch [5/50], Loss: 0.0650, Accuracy: 97.92%\n",
      "Validation Loss: 0.1175, Validation Accuracy: 96.67% \n",
      "\n",
      "Epoch [6/50], Loss: 0.0534, Accuracy: 98.31%\n",
      "Validation Loss: 0.1099, Validation Accuracy: 96.95% \n",
      "\n",
      "Epoch [7/50], Loss: 0.0422, Accuracy: 98.66%\n",
      "Validation Loss: 0.1123, Validation Accuracy: 96.90% \n",
      "\n",
      "Epoch [8/50], Loss: 0.0371, Accuracy: 98.76%\n",
      "Validation Loss: 0.1209, Validation Accuracy: 96.95% \n",
      "\n",
      "Epoch [9/50], Loss: 0.0304, Accuracy: 99.00%\n",
      "Validation Loss: 0.1168, Validation Accuracy: 96.75% \n",
      "\n",
      "Epoch [10/50], Loss: 0.0268, Accuracy: 99.13%\n",
      "Validation Loss: 0.1268, Validation Accuracy: 96.94% \n",
      "\n",
      "Epoch [11/50], Loss: 0.0216, Accuracy: 99.23%\n",
      "Validation Loss: 0.1413, Validation Accuracy: 96.74% \n",
      "\n",
      "Epoch [12/50], Loss: 0.0213, Accuracy: 99.26%\n",
      "Validation Loss: 0.1466, Validation Accuracy: 96.66% \n",
      "\n",
      "Epoch [13/50], Loss: 0.0191, Accuracy: 99.35%\n",
      "Validation Loss: 0.1365, Validation Accuracy: 97.03% \n",
      "\n",
      "Epoch [14/50], Loss: 0.0196, Accuracy: 99.31%\n",
      "Validation Loss: 0.1416, Validation Accuracy: 97.15% \n",
      "\n",
      "Epoch [15/50], Loss: 0.0146, Accuracy: 99.50%\n",
      "Validation Loss: 0.1716, Validation Accuracy: 96.67% \n",
      "\n",
      "Epoch [16/50], Loss: 0.0171, Accuracy: 99.44%\n",
      "Validation Loss: 0.1612, Validation Accuracy: 96.82% \n",
      "\n",
      "Epoch [17/50], Loss: 0.0120, Accuracy: 99.59%\n",
      "Validation Loss: 0.1581, Validation Accuracy: 97.03% \n",
      "\n",
      "Epoch [18/50], Loss: 0.0132, Accuracy: 99.54%\n",
      "Validation Loss: 0.1634, Validation Accuracy: 96.98% \n",
      "\n",
      "Epoch [19/50], Loss: 0.0134, Accuracy: 99.52%\n",
      "Validation Loss: 0.1671, Validation Accuracy: 97.00% \n",
      "\n",
      "Epoch [20/50], Loss: 0.0119, Accuracy: 99.56%\n",
      "Validation Loss: 0.1876, Validation Accuracy: 96.89% \n",
      "\n",
      "Epoch [21/50], Loss: 0.0124, Accuracy: 99.58%\n",
      "Validation Loss: 0.1625, Validation Accuracy: 97.10% \n",
      "\n",
      "Epoch [22/50], Loss: 0.0144, Accuracy: 99.54%\n",
      "Validation Loss: 0.1873, Validation Accuracy: 96.88% \n",
      "\n",
      "Epoch [23/50], Loss: 0.0134, Accuracy: 99.51%\n",
      "Validation Loss: 0.1791, Validation Accuracy: 96.89% \n",
      "\n",
      "Epoch [24/50], Loss: 0.0080, Accuracy: 99.73%\n",
      "Validation Loss: 0.1617, Validation Accuracy: 97.20% \n",
      "\n",
      "Epoch [25/50], Loss: 0.0118, Accuracy: 99.61%\n",
      "Validation Loss: 0.1983, Validation Accuracy: 96.70% \n",
      "\n",
      "Epoch [26/50], Loss: 0.0127, Accuracy: 99.59%\n",
      "Validation Loss: 0.2038, Validation Accuracy: 96.90% \n",
      "\n",
      "Epoch [27/50], Loss: 0.0101, Accuracy: 99.65%\n",
      "Validation Loss: 0.1905, Validation Accuracy: 96.99% \n",
      "\n",
      "Epoch [28/50], Loss: 0.0142, Accuracy: 99.55%\n",
      "Validation Loss: 0.1881, Validation Accuracy: 97.17% \n",
      "\n",
      "Epoch [29/50], Loss: 0.0094, Accuracy: 99.67%\n",
      "Validation Loss: 0.2014, Validation Accuracy: 96.98% \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, labels)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda/envs/ail721/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/ail721/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0.0\n",
    "    total_val = 0\n",
    "    correct_val =0\n",
    "    for images, labels in train_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in val_dataloader:\n",
    "            batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "            outputs = model(batch_data)\n",
    "            loss  = loss_function(outputs,batch_labels)\n",
    "            val_loss+=loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += batch_labels.size(0)\n",
    "            correct_val += (predicted == batch_labels).sum().item()\n",
    "\n",
    "    \n",
    "    train_loss = running_loss / len(train_dataloader)\n",
    "    val_loss = val_loss / len(val_dataloader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}% \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ail721",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
